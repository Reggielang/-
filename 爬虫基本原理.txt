爬虫基本原理
1. 请求网站并提取数据的自动化程序

爬虫基本流程
1.发起请求
通过HTTP库向目标站点发送request， 请求可以包括额外的headers等信息，等待服务器响应。


2. 获取响应内容 
如果服务器正常响应，会得到response，类型可能为HTML，json字符串，二进制数据（如图片，视频等）


3.解析内容
得到的内容是HTML， 可以用正则表达式进行解析，可能也是json文件，可以直接转为json对象解析，也可以是二进制数据，可以做保存或者进一步处理。


4. 保存数据
可以存为文本，也可以保存至数据库，或者特定格式的文件。

request中包含什么？
请求方式，主要有GET,POST 两种类型（GET请求主要包含在URL里，POST需要填写一个完整的表单进行提交，才能进行POST请求）
请求头，包含请求时的头部信息，比如user-agent ,host cookies等信息
请求URL，就是统一资源定位符，如一个文档，一个图片，视频可以用URL作为唯一确定。
请求体，请求时额外的数据，如表单提交时的表单数据

response中包含什么？
响应状态，也就是响应状态码，200，502等 
响应头，如内容类型，内容长度，服务器信息，以及cookies等
响应体，最主要的信息，包含了请求的资源的内容，HTML，图片，视频等

能抓取哪些数据？
1.文本信息
2.图片，视频通常获取为二进制文件
3.其他，比如文档等

如何解析？
1.直接处理
2.Json解析
3.正则表达式
4.BeautifulSoup
5.PyQuery
6.XPath

为什么抓取数据和浏览器看到的不一样?
因为通过request请求,获得的代码没有渲染，而那些数据都是经过后期JS渲染之后的数据（通过Ajax请求）

怎么解决JS渲染的问题？
1.分析Ajax请求
2.selenium/webdriver (自动模拟了JS的渲染)
3.splash

可以怎么保存数据？
1.纯文本文件
2.关系型数据库中
3.非关系数据库